% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={RS notebook},
  pdfauthor={Sohyun Park},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{RS notebook}
\author{Sohyun Park}
\date{4/2/25}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[boxrule=0pt, sharp corners, borderline west={3pt}{0pt}{shadecolor}, enhanced, frame hidden, breakable, interior hidden]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

This is a Quarto book.

To learn more about Quarto books visit
\url{https://quarto.org/docs/books}.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{+} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2
\end{verbatim}

\bookmarksetup{startatroot}

\hypertarget{introduction-to-remote-sensing}{%
\chapter{Introduction to Remote
Sensing}\label{introduction-to-remote-sensing}}

This week is about basic of Reomote Sensing. It is about ``What is
reomote sensing?'' and about ``how it works''.

\hypertarget{what-is-remote-sensing}{%
\subsection{What is remote sensing?}\label{what-is-remote-sensing}}

NASA defines remote sensing as \textbf{acquiring information from a
distance}

Remote sensing is a technology that obtains information from a distance
without contact with the observed object. It uses electromagnetic waves
reflected or emitted from objects to investigate the components, types,
and states of objects. In the case of ocean remote sensing, ocean
currents can be estimated by measuring water temperature with an
infrared sensor of an artificial satellite, the structure of upwelling
or eddies can be identified, and the ocean circulation structure can
also be understood. In the case of meteorological remote sensing, cloud
temperature, classification, dust, ozone content, wind speed, etc. can
be observed. Remote sensing is also used to monitor glacier and volcanic
activity, and to study abnormal climate caused by El NiÃ±o.

\hypertarget{type-of-sensors}{%
\subsection{Type of sensors}\label{type-of-sensors}}

When we use Remote sensing we have to collet data by various of sensors.
We can collect data by

\begin{itemize}
\item
  Satellites
\item
  Phones(aerial imagery)
\item
  Drones
\item
  Phones
\item
  Free standing on the ground or sea
\end{itemize}

\includegraphics{./images/paste-070EE831.png}

Source for this image
https://www.industrytap.com/remote-sensing-sustainable-land-use/33218

\hypertarget{two-types-of-remote-sensing-sensors}{%
\subsection{Two types of remote sensing
sensors}\label{two-types-of-remote-sensing-sensors}}

There are two Type of sensors; Passive sensors and Active sensors. Let's
see more specifically.

\hypertarget{passive-sensors}{%
\subsection{Passive sensors}\label{passive-sensors}}

This sensors don't emit anytning and use energy that is available. And
they detecting reflected energy(in electromagnetic waves) from the sun.
For example, human eye, camera and satellite sonsor.

\hypertarget{active-sensors}{%
\subsection{Active sensors}\label{active-sensors}}

This type of sensors have an energy source for illumination and actively
emits electormagnetic waves and then waits to receive. Electromagnetic
radiation propagates as waves. So we can see through clouds, volcanic
ash, atmospheric conditions and also collect data at night. Such as
Radar, X-ray and LiDAR.

\includegraphics{./images/paste-FF22A002.png}

\includegraphics{./.pdf}

Passive and active sensors systems working principles.
Source:\href{source:\%20https://www.researchgate.net/figure/Passive-and-active-sensors-systems-working-principles-24_fig2_344464269}{Nadhir
Al-Ansari}

\hypertarget{causes-of-bidirectional-reflectance-distribution-functions}{%
\subsection{Causes of bidirectional reflectance distribution
functions}\label{causes-of-bidirectional-reflectance-distribution-functions}}

Sensors collect data from energy being reflected from the surface that
is smooth or diffuse. When electromagnetic waves are reflected from the
surface , the waves can be linked to surface properties - roughness,
shape, orientation, moisture, salinity and density. Furthermore, SAR
data less commonly documented surface interactions.

\includegraphics{./images/paste-B1C42757.png}

Source:
\href{https://www.umb.edu/spectralmass/terra_aqua_modis/modis}{Professor
Crystal Schaaf's Lab}

\hypertarget{explore-the-4-resolutions-of-remotely-sensed-data}{%
\subsection{Explore the 4 resolutions of remotely sensed
data}\label{explore-the-4-resolutions-of-remotely-sensed-data}}

Remotely sensed data and applications will vary based on the four
resolutions.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Spatial

  It is the size of the raster cells(grid per pixels). It's range
  between 10cm and several kilometers.

  \includegraphics{./images/paste-69B7DCB3.png}

  Source https://andrewmaclachlan.github.io/CASA0023-lecture-1/\#54
\item
  Spectral

  Images seen by the human eye are perceived as wavelengths of red,
  green, and blue, which are visible light rays. A color different from
  the wavelength reflected by the object is recognized as the color
  absorbed. However, we are subject to the constraints of the
  atmospheric window (water vapor, ozone, carbon dioxide and atmospheric
  molecules block part of the spectrum). Therefore, we can observe it
  only where it is not absorbed by the atmosphere.

  We classify the type or spectral resolution according to the number of
  bands we observe. Each band is usually provided as a separate raster
  layer. This means that the spectral signature can be either discrete
  or continuous.

  \includegraphics{./images/paste-AF9F0A53.png}

  Source:
  \href{https://earthdata.nasa.gov/learn/backgrounders/remote-sensing\#orbits}{NASA
  Science}
\item
  Temporal

  This means that the revisit time of the sensor needs to be considered.
  For example, return visit times are daily, every 7 days or upon
  request. Also, lower resolution means larger pixels.
\item
  Radiometric

  The ability of a sensor to identify and display small differences in
  energy. Higher means more sensitive.

  \begin{itemize}
  \item
    8 bits = 256 possible values
  \item
    4 bits = 16 possible values
  \end{itemize}
\end{enumerate}

Furthermore, we have to consider type of orbit. There are two type of
orbits. First, geosynchronous orbit (GSO) is that satellite matches the
Earth's rotation. Second, geostationary orbit, this orbit holds same
position, usually only for communications but some sensors are
geostationary.

\includegraphics{./images/paste-45BCDEA4.png}

Source:
\href{https://www.americanscientist.org/article/fifty-years-of-earth-observation-satellites}{American
Scientist}

\hypertarget{applications}{%
\section{Applications}\label{applications}}

\hypertarget{personal-reflection}{%
\section{Personal Reflection}\label{personal-reflection}}

Before entering CASA, I majored in cadastral science in undergraduate
and had 3 years of experience working for a company that did cadastral
surveying and spatial information analysis. I learned about Remote
Sensing Introduction 9 years ago when I was an undergraduate. Based on
this, I received training on a project to create a flood trace map when
I work as a junior engineer at company.

However, this module is an updated version of the knowledge I have
previously learned and acquired. I was amazed at how much the resolution
has improved. The module also taught us that improvements in remote
sensing satellites such as the higher resolution Sentinel and Google
Earth Enngine (GEE) allow for a wide range of analyzes such as
object-based image detection. In this week's module, I was able to
review the basics and principles of remote sensing that I had learned in
the past and learned about advanced technology.

\bookmarksetup{startatroot}

\hypertarget{portfolio-tools}{%
\chapter{Portfolio tools}\label{portfolio-tools}}

This week we will be learn about

\bookmarksetup{startatroot}

\hypertarget{remote-sensing-data}{%
\chapter{Remote sensing data}\label{remote-sensing-data}}

This week we will learn about `corrections' and `data joining annd
enhancement'.

\hypertarget{corrections}{%
\subsection{Corrections}\label{corrections}}

Sometimes images obtained by remote sensing may contain defects due to
sensor, atmosphere, terrain, so pre-processing is required.

A typical example is when Landsat7's scan line corrector fails. It moves
in a zigzag motion and the corrector normalizes the image. However, it
is difficult to use with a method developed for estimating gaps, called
gap filling.

\includegraphics{./images/paste-99A45A8B.png}

Source:\href{https://www.usgs.gov/landsat-missions/landsat-7?qt-science_support_page_related_con=0\#qt-science_support_page_related_con}{USGS}

\begin{itemize}
\item
  Geometric correction

  Collecting remotely sensed data can cause distortion due to viewing
  angle, topography (slope rather than flat areas), wind, and Earth's
  rotation.

  Thus, using geographic maps, other images, and GPS data from handheld
  devices, ground control points are identified to match known points in
  the image to a reference data set.

  The model with the lowest RMSE is the best fit. Jensen sets the RMSE
  value to 0.5. You can usually add more GCPs to reduce the RMSE.

  This may shift the data slightly, so the final raster needs to be
  resampled. Resampling methods include nearest neighbor, linear, cubic,
  and cubic spline.
\end{itemize}

\includegraphics{./images/paste-0481E9FB.png}

Source:\href{https://www2.geog.soton.ac.uk/users/trevesr/obs/rseo/geometric_correction.html}{Richard
Treves}

\begin{itemize}
\item
  Atmospheric correction

  Atmospheric correction is a process used in remote sensing to correct
  for the effects of the Earth's atmosphere on the remotely sensed data.
  The Earth's atmosphere is composed of various gases, particles, and
  water vapor, which can absorb, scatter, and reflect the
  electromagnetic radiation from the sun or the Earth's surface. These
  atmospheric effects can distort or obscure the signals received by
  remote sensors, leading to errors in the interpretation of the data.

  There are various methods for atmospheric correction, including the
  use of empirical models, such as the Dark Target or Deep Blue
  algorithms, and physical models, such as the MODTRAN or 6S models. The
  choice of method depends on the specific application, the sensor
  characteristics, and the atmospheric conditions at the time of data
  acquisition.

  \includegraphics{./images/paste-6860930B.png}

  Source:\href{https://medium.com/nerd-for-tech/atmospheric-correction-of-satellite-images-using-python-42128504afc3}{USGS}
\item
  Empirical line correction

  Empirical correction in remote sensing refers to a type of atmospheric
  correction that is based on statistical relationships between the
  remotely sensed data and ground truth measurements.

  This methods are particularly useful for sensors that lack the
  spectral resolution or radiometric accuracy to accurately model the
  atmospheric effects using physical models.

  \includegraphics{./images/paste-97BC21C1.png}

  Source:\href{https://www.researchgate.net/figure/Example-of-an-empirical-line-using-two-targets-of-contrasting-albedo_fig1_241396033}{Source:
  David P. Groeneveld}
\item
  Ortho-rectification correction

  In satellite images, distortion occurs due to the shading effect in
  images taken of mountain areas with severe topography. In
  consideration of this distortion, all points in the data are corrected
  so that they have the same shape as seen from a vertical position like
  a map. It is called -rectification correction.

  In order to generate orthocorrection, the image to be orthocorrected,
  satellite image, aerial photograph, etc., digital elevation model
  (DEM) of the image area to be corrected, ground control point (GCP),
  and auxiliary data of the image are required.

  Ortho-rectification correction can be performed using various
  techniques, including photogrammetry, lidar, and radar.

  \includegraphics{./images/paste-A1556D99.png}

  Orthorectification creates a final product whereby each pixel in the
  image is depicted as if it were collected from directly overhead or as
  close to this as possible. In the graphic above, you can see a path
  through the forest going from the northwest to the southeast. On the
  left is the original image, and on the right is the orthorectified
  image. In the orthorectified version, you can see that the path is now
  nearly straight after the influence of topography has been removed
  from the image. (Graphic Credit: David DiBiase, Penn State
  University).
  Source:\href{https://apollomapping.com/blog/g-faq-orthorectification-part}{Apollo
  Mapping, 2016}
\item
  Radiometric calibration

  This content mainly applies to optical sensor images, and image data
  acquisition from satellites is when light incident from the sun is
  reflected by an object on the surface of the earth and then detected
  by the observation sensor of the satellite, and sunlight is scattered
  and absorbed in the process of passing through the atmosphere. , is
  reflected, which means preprocessing to correct it.

  The influence of the atmosphere weakens the intensity of sunlight
  incident on the sensor, and consequently affects the brightness of
  image data. In order to correct this, correction is performed using an
  atmospheric model, which is performed by an atmospheric model created
  by actual observations or calculations.

  The atmospheric model can estimate the amount of scattering,
  absorption, and reflection corresponding to each wavelength and the
  intensity of solar incident light by inserting factors such as the
  altitude angle of the sun and meteorological factors at the time of
  observation. According to this algorithm, the brightness of the
  original image data value can be corrected.

  \includegraphics{./images/paste-F675F01F.png}

  Source:\href{https://www.ncl.ac.uk/tcmweb/bilko/module7/lesson3.pdf}{Newcastle
  Univesrity}
\end{itemize}

\hypertarget{data-joining-and-enhancement}{%
\subsection{Data joining and
enhancement}\label{data-joining-and-enhancement}}

\hypertarget{feathering}{%
\subsubsection{Feathering}\label{feathering}}

Feathering helps to eliminate these visible seams or transitions by
blending the overlapping areas of adjacent images or data sets together.
The goal of feathering is to create a seamless composite image that
appears as if it was collected as a single image or data set.

According to Jensen

\begin{itemize}
\item
  Within the overlap area an representative sample is taken
\item
  A histogram is extracted from the base image
\item
  It is then applied to image to using a \textbf{histogram matching
  algorithm}
\item
  This gives similar brightness values of the two images
\item
  Next feathering is conducted
\end{itemize}

\includegraphics{./images/paste-F98F079E.png}

Source:\href{https://www.l3harrisgeospatial.com/docs/mosaicseamless.html}{Harris
Geospatial}

\hypertarget{image-enhancement}{%
\subsubsection{Image enhancement}\label{image-enhancement}}

There are several methods to enhance the images. Representatively, we
can enhance it through contrast enhancement. The goal of contrast
enhancement is to increase the contrast between different features in
the image, making it easier to distinguish between them and extract
useful information. For example, we can use stretching. This technique
involves expanding the range of pixel values in an image to increase the
contrast between dark and light areas. This can help to enhance the
visibility of subtle features in the image.

\begin{figure}

{\centering \includegraphics{./images/paste-F110336A.png}

}

\caption{Source:\href{https://www.earthdatascience.org/courses/use-data-open-source-python/multispectral-remote-sensing/intro-naip/}{EarthLab}}

\end{figure}

\hypertarget{applications-1}{%
\section{Applications}\label{applications-1}}

\hypertarget{personal-reflection-1}{%
\section{Personal Reflection}\label{personal-reflection-1}}

In Korea, I took the exam when I obtained a license related to surveying
and geospatial information. In this test, the problem of image
correction was frequently presented in the remote sensing subject.
Thanks to this, I was aware of the importance of correction in
performing remote sensing. In fact, after joining the company, I felt
that it was more important to obtain reliable data by correcting it
later than collecting satellite data. With this week's class, I once
again thought about the importance of image correction. Before this
week's class, I knew about the basic principles, but I was able to learn
exactly why each correction is done and how it is done.

\bookmarksetup{startatroot}

\hypertarget{policy-applications}{%
\chapter{Policy applications}\label{policy-applications}}

\hypertarget{applications-2}{%
\section{Applications}\label{applications-2}}

\hypertarget{personal-reflection-2}{%
\section{Personal Reflection}\label{personal-reflection-2}}

\bookmarksetup{startatroot}

\hypertarget{introduction-to-google-earth-engine}{%
\chapter{Introduction to Google Earth
Engine}\label{introduction-to-google-earth-engine}}

In this week, we will figure out ``What is Google Earth Engine(GEE)''
and

GEE is ``Geospatial'' processing service. It permits geospatial analysis
at scale.

https://youtu.be/gKGOeTFHnKY

\hypertarget{the-set-up-of-gee}{%
\subsection{The set up of GEE}\label{the-set-up-of-gee}}

GEE has a image data as a raster(has bands) and Feature as a vector.
Feature has geometry and attributes. Furthermore, Image stack called
ImageCollection annd Feature stack called FeatureCollection.

Gee uses javascript(one of website programming language)

\{// Use curly brackets \{\} to make a dictionary of key:value pairs.\}
var object = \{ foo: `bar', baz: 13, stuff: {[}`this', `that', `the
other thing'{]} \}; print(`Print foo:', object{[}`foo'{]});

Introduction to JavaScript for Earth Engine. Source:
\href{https://developers.google.com/earth-engine/tutorials/tutorial_js_01}{GEE}

\hypertarget{client-vs-server}{%
\subsubsection{Client vs Server}\label{client-vs-server}}

Within GEE we have code that runs on the client side and server side.
Client side is the browser. Server side is on the server where data is
stored. Any thing that has \textbf{\emph{ee}} in front of it is stored
on the server.

\includegraphics{./images/paste-1097464A.png}

Client vs Server side. Source:
\href{https://www.pinterest.co.uk/pin/764837949191948083/}{pintrest/codeboxx}

\hypertarget{scale}{%
\subsubsection{Scale}\label{scale}}

Scale in GEE refers to pixel resolution. It is set by the output(not by
input). GEE collects the image to fit a 256x256 grid and GEE select the
pyramid with the closest scale to that of your analysis and re-samples
as needed. When we do re-sample, it uses nearest neighbor by default.

\includegraphics{./images/paste-80D175DE.png}

Scale. Source:
\href{https://developers.google.com/earth-engine/guides/scale}{GEE}

Let's see an example, first load an image

var image = ee.Image(`LANDSAT/LC08/C01/T1/LC08\_044034\_20140318'); var
rgbVis = \{ bands: {[}`B4', `B3', `B2'{]}, min: 5964.56, max: 11703.44
\}; Map.addLayer(image, rgbVis, ``Landsat 8'');

Scale. Source:
\href{https://developers.google.com/earth-engine/guides/scale}{GEE}

Next, select a band 4 and then change the scale

var band\_4 = image.select(`B4'); var printAtScale = function(scale) \{
print(`Pixel value at'+scale+' meters scale', band\_4.reduceRegion(\{
reducer: ee.Reducer.first(), geometry: band\_4.geometry().centroid(), //
The scale determines the pyramid level from which to pull the input
scale: scale \}).get(`B4')); \}; printAtScale(10); // 8883
printAtScale(30); // 8883 printAtScale(50); // 8337 printAtScale(70); //
9215 printAtScale(200); // 8775 printAtScale(500); // 8300 Copy Code

Source:
\href{https://code.earthengine.google.com/82d6c28210a115f2446c0ca8e7a65e51}{Code
example}

\hypertarget{projection}{%
\subsubsection{Projection}\label{projection}}

GEE converts all data into the Mercator projection(EPSG:3867). As a
result, the operations of the projection are decided by the output.

\includegraphics{./images/paste-1BDFAF9D.png}

Source:
\href{https://developers.google.com/earth-engine/guides/projections}{GEE}

\hypertarget{gee-in-actionhow-we-use-it}{%
\subsection{GEE in action(how we use
it)}\label{gee-in-actionhow-we-use-it}}

\hypertarget{building-blocks-of-gee}{%
\subsubsection{Building blocks of GEE}\label{building-blocks-of-gee}}

Object can be vector, raster, feature, string and number. Each of
objects belong to a class and each class have specific functions.

\includegraphics{./images/paste-313B53C6.png}

Object classes. Source:
\href{https://developers.google.com/earth-engine/guides/objects_methods_overview}{GEE}

\hypertarget{what-does-gee-look-like}{%
\subsubsection{What does GEE look like}\label{what-does-gee-look-like}}

\includegraphics{./images/paste-59C13A06.png}

Source:
\href{https://andrewmaclachlan.github.io/CASA0023-lecture-5/\#31}{Form
of GEE}

\hypertarget{typical-processes-in-gee}{%
\subsubsection{Typical processes in
GEE}\label{typical-processes-in-gee}}

After we have lots of images(raster data) and these belong to an
imagecollection. We can process geometry operations, methods and
applications.

\begin{itemize}
\item
  Geometry operations

  \begin{itemize}
  \item
    Joins
  \item
    Zonal statistics
  \item
    Filtering of images or specific values
  \end{itemize}
\item
  Methods

  \begin{itemize}
  \item
    Machine learning
  \item
    Supervised and unsupervised classification
  \item
    Deep learning with Tensor Flow
  \item
    Exploring relationship between variables
  \item
    Exploring relationship between variables
  \end{itemize}
\item
  Applications

  \begin{itemize}
  \item
    Online charts
  \item
    Scalable geopspatial applications with GEE data
  \item
    These let us query the data with a user interface that then updates
    the results
  \end{itemize}
\end{itemize}

\hypertarget{reducing-images-by-region}{%
\subsubsection{Reducing images by
region}\label{reducing-images-by-region}}

We load an image collection from a dates and place and want to reduce
the collection to the extreme values for each pixel. In GEE this is
termed \textbf{reduceRegion().} If we want to use feature collection
with many polygons we can do it by \textbf{image.reduceRegions().}

\includegraphics{./images/paste-E4392F67.png}

Source:
\href{https://developers.google.com/earth-engine/guides/reducers_reduce_region}{GEE}

\hypertarget{reducing-images-by-neighbourhoods}{%
\subsubsection{Reducing images by
neighbourhoods}\label{reducing-images-by-neighbourhoods}}

We can use image neighbors instead of using polygons to reduce the
collection.

\includegraphics{./images/paste-22B32BD6.png}

Source:
\href{https://developers.google.com/earth-engine/guides/reducers_reduce_neighborhood}{GEE}

\hypertarget{joins-and-filtering}{%
\subsubsection{Joins and filtering}\label{joins-and-filtering}}

We can \textbf{join} image collections and feature collections. To use
joins we have to put them within a \textbf{filter}.

\begin{itemize}
\item
  The \texttt{leftField} is the index (or attribute) in the primary data
\item
  The \texttt{rightField} is the secondary data
\end{itemize}

\hypertarget{applications-3}{%
\section{Applications}\label{applications-3}}

\hypertarget{personal-reflection-3}{%
\section{Personal Reflection}\label{personal-reflection-3}}

This week we learned about Google Earth Engine (GEE). In fact, before I
studied GEE, I had Google Earth installed on my personal computer. The
reason is that I wanted to see landmarks around the world through 3D
building information provided by Google. At this time, for the first
time, I found out that Google Earth is basically using LandSAT8(What we
learned in previous week) satellite images for the entire earth,
although it varies depending on the region. In this lecture, I created
GEE account and personally experienced its advantages. I was surprised
by the fact that if you sign up for GEE, you can program yourself and
that anyone can view satellite data from around the world free of
charge. I was also surprised that there was an easy to follow
instruction manual.

\bookmarksetup{startatroot}

\hypertarget{classification}{%
\chapter{Classification}\label{classification}}

\hypertarget{how-to-classify-remotely-sensed-data}{%
\subsection{How to classify remotely sensed
data}\label{how-to-classify-remotely-sensed-data}}

\hypertarget{classification-trees}{%
\subsubsection{Classification trees}\label{classification-trees}}

\begin{itemize}
\item
  Classify data into two or more discrete categories
\item
  Output variable is categoriesed such as religion, sex, nationality
\item
  Top-down approach
\item
  The final leaves can be a mixture of the categories(impure), so we
  quantify this with the Gini Impurity

  \includegraphics{./images/paste-E98859C4.png}
\end{itemize}

Source:\href{https://www.saedsayad.com/decision_tree.htm}{An
Introduction to Data Science, Dr Saed Sayad}

\hypertarget{regression-trees}{%
\subsubsection{Regression trees}\label{regression-trees}}

\begin{itemize}
\item
  Regression trees is decision tree model with regression
\item
  Output variable is continuous values such as height, weight or
  temperature
\item
  Bottom-up approach
\item
  Subset the data into smaller chunks

  \includegraphics{./images/paste-F95DFBD4.png}

  Source:\href{https://medium.datadriveninvestor.com/how-do-regression-trees-work-94999c5105d}{Luka
  Beverin}
\end{itemize}

\hypertarget{overfitting}{%
\subsubsection{Overfitting}\label{overfitting}}

\begin{itemize}
\item
  What if we have a leaf with just one person or one pixel value? =
  \textbf{overfitting}

  \begin{itemize}
  \item
    Bias means difference between predicted value and true
    value(\textbf{oversimplifies model)}
  \item
    Variance is variability of model for a given point
  \end{itemize}
\end{itemize}

\includegraphics{./images/paste-F0B4E05F.png}

Source:\href{https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229}{Seema
Singh}

\hypertarget{prevent-overfitting}{%
\subsubsection{Prevent overfitting}\label{prevent-overfitting}}

\begin{itemize}
\item
  We can fix it by limiting how trees grow, for example we can set a
  minimum number of pixels in a leaf(20 is often used)

  \includegraphics{https://ucfnoix.github.io/CASA0023_Learning_Diary/images/decision-tree-subtrees.png}Source:\href{http://mlwiki.org/index.php/Cost-Complexity_Pruning}{ML
  Wiki}
\item
  Also we can fix it by \textbf{weakest link pruning} (with tree score)

  \begin{itemize}
  \item
    use one less leaf, remove a leaf = \textbf{sub-tree}, SSR will get
    larger = \textbf{termed PRUNING or cost complexity pruning}
  \item
    Sum for the tree
  \item
    Tree score = SSR + tree penalty (alpha) * T (number of leaves)
    \textbf{Lower means better}
  \end{itemize}
\end{itemize}

\begin{itemize}
\item
  There is another method\ldots{} \textbf{Random Forest}

  \begin{itemize}
  \item
    Ensemble machine learning model
  \item
    All decision trees are grown by randomly extracting sub-datasets
  \item
    A single data may be selected multiple times as it allows redundancy
  \item
    Find the overall value which got more values based on all the trees

    \includegraphics{./images/paste-CF6CAF04.png}
  \end{itemize}
\end{itemize}

Source:\href{https://towardsdatascience.com/from-a-single-decision-tree-to-a-random-forest-b9523be65147}{Rosaria
Silipo}

\hypertarget{image-classification}{%
\subsection{Image classification}\label{image-classification}}

There are three types of image classification.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5244}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.4756}}@{}}
\toprule()
\begin{minipage}[b]{\linewidth}\raggedright
Supervised Classification
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Unsupervised Classification
\end{minipage} \\
\midrule()
\endhead
Pattern recognition or machine learning & clustering \\
Parametric (normal distribution) : Maximum likelihood & k-means \\
non parametric (not normal) : Support Vector Machine, Neural Networks &
ISODATA \\
\bottomrule()
\end{longtable}

\includegraphics{./images/paste-0BFC54B9.png}

Source:\href{https://gisgeography.com/supervised-unsupervised-classification-arcgis/}{GIS
Geography}

\hypertarget{applications-4}{%
\section{Applications}\label{applications-4}}

\hypertarget{personal-reflection-4}{%
\section{Personal Reflection}\label{personal-reflection-4}}

As a surveying engineer, I have always been obsessed with accurate
figures. This background is why it is important to choose the model with
the highest accuracy. And even in the real world, it's common to
prioritize accuracy because most of us aim for profit. In this week's
lesson, I learned that classification methods fundamentally analyze data
differently, which affects the ability to build accurate models.
Although I did not fully understand the mathematical principles of each
classification method, my goal is to build a model that is close to
perfection by understanding it more clearly. However, in the field of
social science research, since there is a possibility of understanding a
phenomenon and inducing certain results rather than simply accurately
predicting a phenomenon, interpretability should also be considered.

\bookmarksetup{startatroot}

\hypertarget{classification-the-big-questions-and-accuracy}{%
\chapter{Classification the big questions and
accuracy}\label{classification-the-big-questions-and-accuracy}}

\bookmarksetup{startatroot}

\hypertarget{temperature-and-policy}{%
\chapter{Temperature and policy}\label{temperature-and-policy}}

\bookmarksetup{startatroot}

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{0}{0}
\end{CSLReferences}



\end{document}
