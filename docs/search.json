[
  {
    "objectID": "week4.html#applications",
    "href": "week4.html#applications",
    "title": "4  Policy applications",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nIn this part, I’ll focus on policy 3 ; Expansion of Zero Emission Buildings and figure out what is suitable data & methods and recommended usages.\n\n4.2.1 Data and Methods\n\nLiDAR data: This data can be used to measure the height and area of buildings in an entire urban area. It also recognizes the roof structure and the presence or absence of solar panels. If these factors are visualized and analyzed as data, it will help decision-making on the degree of eco-friendliness of the building\nThermal imaging data: Data collected using sensors that detect the infrared radiation emitted by a building could indicate the presence of an inefficient heating and cooling system in the building. So this will be also help decision-making on the degree of eco-friendliness of the building\n\n\n\n4.2.2 Recommended usages\nThrough these data, policy makers will be able to score buildings with accurate values as data on the eco-friendliy buildings. Buildings are graded based on these scores, and buildings that are not eco-friendly to be remodeled can be improved first. In addition, even for a new building in the design stage, if we find a place to supplement in advance using the two data mentioned above before completing the outer wall, we will obtain benefits in terms of economy and environment."
  },
  {
    "objectID": "week4.html#personal-reflection",
    "href": "week4.html#personal-reflection",
    "title": "4  Policy applications",
    "section": "4.3 Personal Reflection",
    "text": "4.3 Personal Reflection\nI thought this week’s class would be easy because of my experience working with government. However, while doing this assignment, I realized that this is not the case. It is not difficult to hear from a third party about a policy that already exists during class or office hours and understand it. However, it was really difficult to select a specific policy and think about “what is an efficient data collection method” or “what data to collect”. This is also the reason why I wanted to study at CASA. This is because I wanted to support my opinion by collecting data close to accuracy when presenting an opinion on a policy. For the rest of the semester, I decided to learn more about the types of remote sensing data and how to analyze them to make them more specific."
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1 Introduction to Remote Sensing",
    "section": "",
    "text": "This week is about basic of Reomote Sensing. It is about “What is reomote sensing?” and about “how it works”.\n\n\nNASA defines remote sensing as acquiring information from a distance\nRemote sensing is a technology that obtains information from a distance without contact with the observed object. It uses electromagnetic waves reflected or emitted from objects to investigate the components, types, and states of objects. In the case of ocean remote sensing, ocean currents can be estimated by measuring water temperature with an infrared sensor of an artificial satellite, the structure of upwelling or eddies can be identified, and the ocean circulation structure can also be understood. In the case of meteorological remote sensing, cloud temperature, classification, dust, ozone content, wind speed, etc. can be observed. Remote sensing is also used to monitor glacier and volcanic activity, and to study abnormal climate caused by El Niño.\n\n\n\nWhen we use Remote sensing we have to collet data by various of sensors. We can collect data by\n\nSatellites\nPhones(aerial imagery)\nDrones\nPhones\nFree standing on the ground or sea\n\n\nSource for this image https://www.industrytap.com/remote-sensing-sustainable-land-use/33218\n\n\n\nThere are two Type of sensors; Passive sensors and Active sensors. Let’s see more specifically.\n\n\n\nThis sensors don’t emit anytning and use energy that is available. And they detecting reflected energy(in electromagnetic waves) from the sun. For example, human eye, camera and satellite sonsor.\n\n\n\nThis type of sensors have an energy source for illumination and actively emits electormagnetic waves and then waits to receive. Electromagnetic radiation propagates as waves. So we can see through clouds, volcanic ash, atmospheric conditions and also collect data at night. Such as Radar, X-ray and LiDAR.\n\n\nPassive and active sensors systems working principles. Source:Nadhir Al-Ansari\n\n\n\nSensors collect data from energy being reflected from the surface that is smooth or diffuse. When electromagnetic waves are reflected from the surface , the waves can be linked to surface properties - roughness, shape, orientation, moisture, salinity and density. Furthermore, SAR data less commonly documented surface interactions.\n\nSource: Professor Crystal Schaaf’s Lab\n\n\n\nRemotely sensed data and applications will vary based on the four resolutions.\n\nSpatial\nIt is the size of the raster cells(grid per pixels). It’s range between 10cm and several kilometers.\n\nSource https://andrewmaclachlan.github.io/CASA0023-lecture-1/#54\nSpectral\nImages seen by the human eye are perceived as wavelengths of red, green, and blue, which are visible light rays. A color different from the wavelength reflected by the object is recognized as the color absorbed. However, we are subject to the constraints of the atmospheric window (water vapor, ozone, carbon dioxide and atmospheric molecules block part of the spectrum). Therefore, we can observe it only where it is not absorbed by the atmosphere.\nWe classify the type or spectral resolution according to the number of bands we observe. Each band is usually provided as a separate raster layer. This means that the spectral signature can be either discrete or continuous.\n\nSource: NASA Science\nTemporal\nThis means that the revisit time of the sensor needs to be considered. For example, return visit times are daily, every 7 days or upon request. Also, lower resolution means larger pixels.\nRadiometric\nThe ability of a sensor to identify and display small differences in energy. Higher means more sensitive.\n\n8 bits = 256 possible values\n4 bits = 16 possible values\n\n\nFurthermore, we have to consider type of orbit. There are two type of orbits. First, geosynchronous orbit (GSO) is that satellite matches the Earth’s rotation. Second, geostationary orbit, this orbit holds same position, usually only for communications but some sensors are geostationary.\n\nSource: American Scientist"
  },
  {
    "objectID": "week1.html#applications",
    "href": "week1.html#applications",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nThe article by Lopez Ornelas (2016) research the benefits of using remote sensing techniques to assess changes in land use and land cover in the Mexican Water Forest. In this study, land-use changes between 1986 and 2001 in Mexico’s aquatic forests are reviewed over time. It also uses remote sensing technology (satellite imagery and GIS) as a tool to monitor changes in aquatic forests. The authors emphasize the importance of continuously monitoring changes in Mexican aquatic forests using remote sensing technology. SAR data can identify sleep anomalies over a wide spatial range. In this study, the authors used the data to calculate the surface water area fraction (SWAF) of the Amazon River after a drought to identify areas of drought."
  },
  {
    "objectID": "week1.html#personal-reflection",
    "href": "week1.html#personal-reflection",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.3 Personal Reflection",
    "text": "1.3 Personal Reflection\nBefore entering CASA, I majored in cadastral science in undergraduate and had 3 years of experience working for a company that did cadastral surveying and spatial information analysis. I learned about Remote Sensing Introduction 9 years ago when I was an undergraduate. Based on this, I received training on a project to create a flood trace map when I work as a junior engineer at company.\nHowever, this module is an updated version of the knowledge I have previously learned and acquired. I was amazed at how much the resolution has improved. The module also taught us that improvements in remote sensing satellites such as the higher resolution Sentinel and Google Earth Enngine (GEE) allow for a wide range of analyzes such as object-based image detection. In this week’s module, I was able to review the basics and principles of remote sensing that I had learned in the past and learned about advanced technology."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Portfolio tools",
    "section": "",
    "text": "This week we will be learn about Xaringan. It is effective in making digital communication neat and manageable by producing interactive and dynamic presentations.\nI made a presentation by using xaringan about the LiDAR & RADAR. Click here to check my presentation."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3 Remote sensing data",
    "section": "",
    "text": "This week we will learn about ‘corrections’ and ‘data joining annd enhancement’.\n\n\nSometimes images obtained by remote sensing may contain defects due to sensor, atmosphere, terrain, so pre-processing is required.\nA typical example is when Landsat7’s scan line corrector fails. It moves in a zigzag motion and the corrector normalizes the image. However, it is difficult to use with a method developed for estimating gaps, called gap filling.\n\nSource:USGS\n\nGeometric correction\nCollecting remotely sensed data can cause distortion due to viewing angle, topography (slope rather than flat areas), wind, and Earth’s rotation.\nThus, using geographic maps, other images, and GPS data from handheld devices, ground control points are identified to match known points in the image to a reference data set.\nThe model with the lowest RMSE is the best fit. Jensen sets the RMSE value to 0.5. You can usually add more GCPs to reduce the RMSE.\nThis may shift the data slightly, so the final raster needs to be resampled. Resampling methods include nearest neighbor, linear, cubic, and cubic spline.\n\n\nSource:Richard Treves\n\nAtmospheric correction\nAtmospheric correction is a process used in remote sensing to correct for the effects of the Earth’s atmosphere on the remotely sensed data. The Earth’s atmosphere is composed of various gases, particles, and water vapor, which can absorb, scatter, and reflect the electromagnetic radiation from the sun or the Earth’s surface. These atmospheric effects can distort or obscure the signals received by remote sensors, leading to errors in the interpretation of the data.\nThere are various methods for atmospheric correction, including the use of empirical models, such as the Dark Target or Deep Blue algorithms, and physical models, such as the MODTRAN or 6S models. The choice of method depends on the specific application, the sensor characteristics, and the atmospheric conditions at the time of data acquisition.\n\nSource:USGS\nEmpirical line correction\nEmpirical correction in remote sensing refers to a type of atmospheric correction that is based on statistical relationships between the remotely sensed data and ground truth measurements.\nThis methods are particularly useful for sensors that lack the spectral resolution or radiometric accuracy to accurately model the atmospheric effects using physical models.\n\nSource:Source: David P. Groeneveld\nOrtho-rectification correction\nIn satellite images, distortion occurs due to the shading effect in images taken of mountain areas with severe topography. In consideration of this distortion, all points in the data are corrected so that they have the same shape as seen from a vertical position like a map. It is called -rectification correction.\nIn order to generate orthocorrection, the image to be orthocorrected, satellite image, aerial photograph, etc., digital elevation model (DEM) of the image area to be corrected, ground control point (GCP), and auxiliary data of the image are required.\nOrtho-rectification correction can be performed using various techniques, including photogrammetry, lidar, and radar.\n\nOrthorectification creates a final product whereby each pixel in the image is depicted as if it were collected from directly overhead or as close to this as possible. In the graphic above, you can see a path through the forest going from the northwest to the southeast. On the left is the original image, and on the right is the orthorectified image. In the orthorectified version, you can see that the path is now nearly straight after the influence of topography has been removed from the image. (Graphic Credit: David DiBiase, Penn State University). Source:Apollo Mapping, 2016\nRadiometric calibration\nThis content mainly applies to optical sensor images, and image data acquisition from satellites is when light incident from the sun is reflected by an object on the surface of the earth and then detected by the observation sensor of the satellite, and sunlight is scattered and absorbed in the process of passing through the atmosphere. , is reflected, which means preprocessing to correct it.\nThe influence of the atmosphere weakens the intensity of sunlight incident on the sensor, and consequently affects the brightness of image data. In order to correct this, correction is performed using an atmospheric model, which is performed by an atmospheric model created by actual observations or calculations.\nThe atmospheric model can estimate the amount of scattering, absorption, and reflection corresponding to each wavelength and the intensity of solar incident light by inserting factors such as the altitude angle of the sun and meteorological factors at the time of observation. According to this algorithm, the brightness of the original image data value can be corrected.\n\nSource:Newcastle Univesrity\n\n\n\n\n\n\nFeathering helps to eliminate these visible seams or transitions by blending the overlapping areas of adjacent images or data sets together. The goal of feathering is to create a seamless composite image that appears as if it was collected as a single image or data set.\nAccording to Jensen\n\nWithin the overlap area an representative sample is taken\nA histogram is extracted from the base image\nIt is then applied to image to using a histogram matching algorithm\nThis gives similar brightness values of the two images\nNext feathering is conducted\n\n\nSource:Harris Geospatial\n\n\n\nThere are several methods to enhance the images. Representatively, we can enhance it through contrast enhancement. The goal of contrast enhancement is to increase the contrast between different features in the image, making it easier to distinguish between them and extract useful information. For example, we can use stretching. This technique involves expanding the range of pixel values in an image to increase the contrast between dark and light areas. This can help to enhance the visibility of subtle features in the image.\n\n\n\nSource:EarthLab"
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "3  Remote sensing data",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nLi and Xia(2021)investigated the effect of geometric correction on the accuracy of remote sensing reflectance extraction from water using Landsat 8 Operational Land Imager (OLI) images. As a result, it was found that the geometric correction has some effect on the reflectance value of the atmospheric correction image, but the overall effect is insignificant. As a result, the authors emphasize that accurate geometrical correction is critical to extracting remote-sensing reflectance from water using satellite imagery, especially in regions with complex topography. However, as the study design was small sample size, conclusions drawn from this study may require further validation."
  },
  {
    "objectID": "week3.html#personal-reflection",
    "href": "week3.html#personal-reflection",
    "title": "3  Remote sensing data",
    "section": "3.3 Personal Reflection",
    "text": "3.3 Personal Reflection\nIn Korea, I took the exam when I obtained a license related to surveying and geospatial information. In this test, the problem of image correction was frequently presented in the remote sensing subject. Thanks to this, I was aware of the importance of correction in performing remote sensing. In fact, after joining the company, I felt that it was more important to obtain reliable data by correcting it later than collecting satellite data. With this week’s class, I once again thought about the importance of image correction. Before this week’s class, I knew about the basic principles, but I was able to learn exactly why each correction is done and how it is done."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RS notebook",
    "section": "",
    "text": "Hello!"
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "8  Temperature and policy",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThis week’s lecture we will learn aboutUrban Heat Island (UHI) phenomenon through several policy case studies in different cities and countries.\n\n8.1.1 What is Urban Heat Island?\n\nUrban areas obtain comparatively higher atmospheric and surface temperatures than surrounding rural areas due to human activities \n\nSource:EARTH.ORG\nThere is two main factors\n\nMore dark surfaces that retain heat\nLess vegetation that cools the environment\n\n\nSource here:Cidco Smartcity\nBasic solution is making more green spaces in urban area\nIn Barcelona, they have implemented ’Superblocks’ startegy\n\nIncrease pedestrian traffic\nReduce nitrogen oxide\nReduce noise pollution\nIncrease business\n\n\nSource:Beating the Heat: A Sustainable Cooling Handbook for Cities. Image: regenerativedesign.world\n\n\n\nIn western Sydney, they have implemented ’Cool Roads Trail’ startegy\n\nSurface coating did not systematically reduce air temperature during the day or night\nAmbient air temperatures were not lowered as a result of coating roads and carparks, which can potentially be a matter of scale\n\n\n\nSource:Pfautsch, S., & Wujeska-Klause, A. (2021). Cool Roads Trial 2021\n\n\n8.1.2 What data do we need?\n\nEO data(eg.Landsat 8 TIRS Collection 2)\nMeteorological data(Temperature/Wind/Precipitation)\nSpatial data from OpenStreetMap\nCensus data\n\n\n\n8.1.3 Making sense of this\nBefore implement the policy, we have to think about equal access/ distribution or equitable access / distribution or providing environmental justice.\n\nSource:Nikki Erdmann"
  },
  {
    "objectID": "week8.html#applications",
    "href": "week8.html#applications",
    "title": "8  Temperature and policy",
    "section": "8.2 Applications",
    "text": "8.2 Applications"
  },
  {
    "objectID": "week8.html#personal-reflection",
    "href": "week8.html#personal-reflection",
    "title": "8  Temperature and policy",
    "section": "8.3 Personal Reflection",
    "text": "8.3 Personal Reflection\nI’ve heard about Urbann Heat Island in the news. In Seoul in the past, this phenomenon was extreme due to many concrete roads and insufficient green areas. In order to solve this problem, the city of Seoul is solving this problem by creating artificial rivers, rooftop green areas and planting trees. Particularly impressive this week is the Barcelona example. I visited Barcelona for the first time 8 years ago while backpacking. At that time, I remember wandering down the street because it felt like all the same roads because of the blocks and similar buildings in the square shape of Barcelona. At the time, I thought it was nice and uncomfortable to look at, but after learning ‘Superblocks’ startegy from this lecture, I was surprised that square blocks are useful for policy and can further improve the quality of life of citizens."
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Classification2",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nThis week covered more classification methods, how to assess accuracy of classifers and importance of accounting for spatial dependence in classifiers.\n\n7.1.1 Object-based image analysis(OBIA)\n\nSimple Linear Iterative Clustering (SLIC) Algorithm = the most common method for superpixel generation\nSupercells are consider shapes (rather than cells) based on the homogeneity or heterogeneity of cells\nConsists of two parts; Segmentation and classification\nSegmentation: OBIA segments an image grouping small pixels together into vector objects based on similarity \n\nSource:Nowosad 2021\n\n\n\n7.1.2 Sub pixel classification(Spectral Mixture Analysis (SMA)/ Linear spectral unmixing)\nWhat if we have a range of land cover types within one pixel? How can we classify it? Subpixel analysis overcome this limitation by estimating the proportion of different land cover types within each pixel.\n\nSource:MacLachlan et al. 2017\n\n\n7.1.3 Accuracy assessment\nAccuracy is important because it determines the quality of the information. So, after producing and output wee need to assign a accuracy value to it(common to machine learning).\nIn remote sensing we focus on:\n\nProducer accuracy: the fraction of correctly classified pixels (TP) compared to ground truth data(TP+FN)\nUser accuracy: the fraction of correctly classified pixels (TP) relative to all others classified as a particular land cover(TP+FP)\nOverall accuracy: epresents the combined fraction of correctly classified pixels (TP +TN) across all land cover types (TP+FP+FN+TN)\n\n\nSource:Barsi et al. 2018 Accuracy Dimensions in Remote Sensing\n\n\n7.1.4 Spatial cross validation\n\nSpatially partition the folded data\nDealing with spatial autocorrelation by using k-means clustering in each fold\nSupport Vector Machine\nNot available in GEE (but available in R)\n\n\nSpatial visualization of selected test and training observations for cross-validation of one repetition. Random (upper row) and spatial partitioning (lower row). Source:Lovelace et al. 2022"
  },
  {
    "objectID": "week7.html#applications",
    "href": "week7.html#applications",
    "title": "7  Classification2",
    "section": "7.2 Applications",
    "text": "7.2 Applications\nPradhan (2016) conducted this study to develop a landslide risk analysis model using remote sensing and GIS technology in Malaysia. This study focuses on three test areas and uses various remote sensing data such as satellite imagery and land use/land cover maps to extract information related to landslide occurrence. After calculating 10 factors such as soil type and land cover, this study applies a multivariate logistic regression model to model the relationship between landslide occurrence and environmental variables by cross-validating the three research areas. The authors emphasized that this model developed using remote sensing and GIS is effective in identifying and mapping landslide risk areas, and the importance of cross-validation as a means of testing the accuracy of the model."
  },
  {
    "objectID": "week7.html#personal-reflection",
    "href": "week7.html#personal-reflection",
    "title": "7  Classification2",
    "section": "7.3 Personal Reflection",
    "text": "7.3 Personal Reflection\nThis week we learned advanced classifier methods and indicators for accuracy assessmennt. I really enjoyed to try out landcover classification on GEE in the practical. However, on the other hand, \bI thought that the technology to accurately detect and classify objects using these innovative methods could be abused and endanger human life or privacy. Of course, most of these technologies are used in good ways to improve the environment and the quality of life of citizens. However, after learning about ethics as a data scientist in the first semester and learning examples of side effects caused by data processing and misuse of technology, this week’s lecture gave me an opportunity to think about it once again."
  },
  {
    "objectID": "week8.html#aplications",
    "href": "week8.html#aplications",
    "title": "8  Temperature and policy",
    "section": "8.2 Aplications",
    "text": "8.2 Aplications\nAs global warming becomes more severe in modern society, many citizens suffer from heat waves in summer. Lee and Brown(2022) were interesting in that they investigated the relationship between sociodemographic characteristics and heat-related health outcomes using emergency medical service (EMS) incident data (vector data). The study found that areas with a high percentage of impervious surfaces, low percentages of green spaces, non-whites, and people over the age of 65 were more likely to be exposed to heat-related EMS incidents. These results will be able to prioritize accident-prone areas when applying policies to mitigate the urban heat island, thereby mitigating adverse effects on the health of urban residents. This means that policies and resources can be delivered efficiently and first to those who need them most."
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nThis week is about basic of Reomote Sensing. It is about “What is reomote sensing?” and about “how it works”.\n\n1.1.1 What is remote sensing?\nNASA defines remote sensing as acquiring information from a distance\nRemote sensing is a technology that obtains information from a distance without contact with the observed object. It uses electromagnetic waves reflected or emitted from objects to investigate the components, types, and states of objects. In the case of ocean remote sensing, ocean currents can be estimated by measuring water temperature with an infrared sensor of an artificial satellite, the structure of upwelling or eddies can be identified, and the ocean circulation structure can also be understood. In the case of meteorological remote sensing, cloud temperature, classification, dust, ozone content, wind speed, etc. can be observed. Remote sensing is also used to monitor glacier and volcanic activity, and to study abnormal climate caused by El Niño.\n\n\n1.1.2 Type of sensors\nWhen we use Remote sensing we have to collet data by various of sensors. We can collect data by\n\nSatellites\nPhones(aerial imagery)\nDrones\nPhones\nFree standing on the ground or sea\n\n\nSource for this image https://www.industrytap.com/remote-sensing-sustainable-land-use/33218\n\n\n1.1.3 Two types of remote sensing sensors\nThere are two Type of sensors; Passive sensors and Active sensors. Let’s see more specifically.\n\n\n1.1.4 Passive sensors\nThis sensors don’t emit anytning and use energy that is available. And they detecting reflected energy(in electromagnetic waves) from the sun. For example, human eye, camera and satellite sonsor.\n\n\n1.1.5 Active sensors\nThis type of sensors have an energy source for illumination and actively emits electormagnetic waves and then waits to receive. Electromagnetic radiation propagates as waves. So we can see through clouds, volcanic ash, atmospheric conditions and also collect data at night. Such as Radar, X-ray and LiDAR.\n\n\nPassive and active sensors systems working principles. Source:Nadhir Al-Ansari\n\n\n1.1.6 Causes of bidirectional reflectance distribution functions\nSensors collect data from energy being reflected from the surface that is smooth or diffuse. When electromagnetic waves are reflected from the surface , the waves can be linked to surface properties - roughness, shape, orientation, moisture, salinity and density. Furthermore, SAR data less commonly documented surface interactions.\n\nSource: Professor Crystal Schaaf’s Lab\n\n\n1.1.7 Explore the 4 resolutions of remotely sensed data\nRemotely sensed data and applications will vary based on the four resolutions.\n\nSpatial\nIt is the size of the raster cells(grid per pixels). It’s range between 10cm and several kilometers.\n\nSource https://andrewmaclachlan.github.io/CASA0023-lecture-1/#54\nSpectral\nImages seen by the human eye are perceived as wavelengths of red, green, and blue, which are visible light rays. A color different from the wavelength reflected by the object is recognized as the color absorbed. However, we are subject to the constraints of the atmospheric window (water vapor, ozone, carbon dioxide and atmospheric molecules block part of the spectrum). Therefore, we can observe it only where it is not absorbed by the atmosphere.\nWe classify the type or spectral resolution according to the number of bands we observe. Each band is usually provided as a separate raster layer. This means that the spectral signature can be either discrete or continuous.\n\nSource: NASA Science\nTemporal\nThis means that the revisit time of the sensor needs to be considered. For example, return visit times are daily, every 7 days or upon request. Also, lower resolution means larger pixels.\nRadiometric\nThe ability of a sensor to identify and display small differences in energy. Higher means more sensitive.\n\n8 bits = 256 possible values\n4 bits = 16 possible values\n\n\nFurthermore, we have to consider type of orbit. There are two type of orbits. First, geosynchronous orbit (GSO) is that satellite matches the Earth’s rotation. Second, geostationary orbit, this orbit holds same position, usually only for communications but some sensors are geostationary.\n\nSource: American Scientist"
  },
  {
    "objectID": "week2.html#portfolio-tools",
    "href": "week2.html#portfolio-tools",
    "title": "2  Portfolio tools",
    "section": "2.1 Portfolio tools",
    "text": "2.1 Portfolio tools\nThis week we will be learn about"
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Remote sensing data",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThis week we will learn about ‘corrections’ and ‘data joining annd enhancement’.\n\n3.1.1 Corrections\nSometimes images obtained by remote sensing may contain defects due to sensor, atmosphere, terrain, so pre-processing is required.\nA typical example is when Landsat7’s scan line corrector fails. It moves in a zigzag motion and the corrector normalizes the image. However, it is difficult to use with a method developed for estimating gaps, called gap filling.\n\nSource:USGS\n\nGeometric correction\nCollecting remotely sensed data can cause distortion due to viewing angle, topography (slope rather than flat areas), wind, and Earth’s rotation.\nThus, using geographic maps, other images, and GPS data from handheld devices, ground control points are identified to match known points in the image to a reference data set.\nThe model with the lowest RMSE is the best fit. Jensen sets the RMSE value to 0.5. You can usually add more GCPs to reduce the RMSE.\nThis may shift the data slightly, so the final raster needs to be resampled. Resampling methods include nearest neighbor, linear, cubic, and cubic spline.\n\n\nSource:Richard Treves\n\nAtmospheric correction\nAtmospheric correction is a process used in remote sensing to correct for the effects of the Earth’s atmosphere on the remotely sensed data. The Earth’s atmosphere is composed of various gases, particles, and water vapor, which can absorb, scatter, and reflect the electromagnetic radiation from the sun or the Earth’s surface. These atmospheric effects can distort or obscure the signals received by remote sensors, leading to errors in the interpretation of the data.\nThere are various methods for atmospheric correction, including the use of empirical models, such as the Dark Target or Deep Blue algorithms, and physical models, such as the MODTRAN or 6S models. The choice of method depends on the specific application, the sensor characteristics, and the atmospheric conditions at the time of data acquisition.\n\nSource:USGS\nEmpirical line correction\nEmpirical correction in remote sensing refers to a type of atmospheric correction that is based on statistical relationships between the remotely sensed data and ground truth measurements.\nThis methods are particularly useful for sensors that lack the spectral resolution or radiometric accuracy to accurately model the atmospheric effects using physical models.\n\nSource:Source: David P. Groeneveld\nOrtho-rectification correction\nIn satellite images, distortion occurs due to the shading effect in images taken of mountain areas with severe topography. In consideration of this distortion, all points in the data are corrected so that they have the same shape as seen from a vertical position like a map. It is called -rectification correction.\nIn order to generate orthocorrection, the image to be orthocorrected, satellite image, aerial photograph, etc., digital elevation model (DEM) of the image area to be corrected, ground control point (GCP), and auxiliary data of the image are required.\nOrtho-rectification correction can be performed using various techniques, including photogrammetry, lidar, and radar.\n\nOrthorectification creates a final product whereby each pixel in the image is depicted as if it were collected from directly overhead or as close to this as possible. In the graphic above, you can see a path through the forest going from the northwest to the southeast. On the left is the original image, and on the right is the orthorectified image. In the orthorectified version, you can see that the path is now nearly straight after the influence of topography has been removed from the image. (Graphic Credit: David DiBiase, Penn State University). Source:Apollo Mapping, 2016\nRadiometric calibration\nThis content mainly applies to optical sensor images, and image data acquisition from satellites is when light incident from the sun is reflected by an object on the surface of the earth and then detected by the observation sensor of the satellite, and sunlight is scattered and absorbed in the process of passing through the atmosphere. , is reflected, which means preprocessing to correct it.\nThe influence of the atmosphere weakens the intensity of sunlight incident on the sensor, and consequently affects the brightness of image data. In order to correct this, correction is performed using an atmospheric model, which is performed by an atmospheric model created by actual observations or calculations.\nThe atmospheric model can estimate the amount of scattering, absorption, and reflection corresponding to each wavelength and the intensity of solar incident light by inserting factors such as the altitude angle of the sun and meteorological factors at the time of observation. According to this algorithm, the brightness of the original image data value can be corrected.\n\nSource:Newcastle Univesrity\n\n\n\n3.1.2 Data joining and enhancement\n\n3.1.2.1 Feathering\nFeathering helps to eliminate these visible seams or transitions by blending the overlapping areas of adjacent images or data sets together. The goal of feathering is to create a seamless composite image that appears as if it was collected as a single image or data set.\nAccording to Jensen\n\nWithin the overlap area an representative sample is taken\nA histogram is extracted from the base image\nIt is then applied to image to using a histogram matching algorithm\nThis gives similar brightness values of the two images\nNext feathering is conducted\n\n\nSource:Harris Geospatial\n\n\n3.1.2.2 Image enhancement\nThere are several methods to enhance the images. Representatively, we can enhance it through contrast enhancement. The goal of contrast enhancement is to increase the contrast between different features in the image, making it easier to distinguish between them and extract useful information. For example, we can use stretching. This technique involves expanding the range of pixel values in an image to increase the contrast between dark and light areas. This can help to enhance the visibility of subtle features in the image.\n\n\n\nSource:EarthLab"
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4  Policy applications",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nThis week is about policy applications, and this diary focused on Zero Emission Tokyo Strategy\n\n4.1.1 Introduction\nIn 2018, the city of Tokyo announced “The Zero Emission Tokyo Strategy”. This strategy is a plan to achieve zero greenhouse gas emissions in the city of Tokyo by 2050. Tokyo is the most populous city in Japan. As the population increases, urban expansion is accelerating, and as a result, the green area ratio is relatively reduced by constructing urban structures such as paved roads and buildings, and the city is getting hotter and hotter. We can see the improvement direction for this through this policy report.\n\nSource: Zero Emission Tokyo Strategy\n\n\n4.1.2 Aim\n\nEnergy Savings and Efficiency(policy2): Increase use of renewable energy sources such as solar and wind power by 30% and reduce energy consumption by 38% by 2030\n\n\nSource: Zero Emission Tokyo Strategy\n\nZero emission Transport(policy 4): Transition to low-emission transport(electric and fuel cell vehicles) and promote public transport \nSource: Zero Emission Tokyo Strategy\n\nEmissions-Free Buildings(policy 3): Promote the use of energy-efficient and emission-free buildings\n\nSource: Zero Emission Tokyo Strategy"
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nIn this week, we will figure out “What is Google Earth Engine(GEE)” and\nGEE is “Geospatial” processing service. It permits geospatial analysis at scale.\n\n5.1.1 The set up of GEE\nGEE has a image data as a raster(has bands) and Feature as a vector. Feature has geometry and attributes. Furthermore, Image stack called ImageCollection annd Feature stack called FeatureCollection.\nGEE uses javascript(one of website programming language)\n\n5.1.1.1 Client vs Server\nWithin GEE we have code that runs on the client side and server side. Client side is the browser. Server side is on the server where data is stored. Any thing that has ee in front of it is stored on the server.\n\nSource: pintrest/codeboxx\n\n\n5.1.1.2 Scale\nScale in GEE refers to pixel resolution. It is set by the output(not by input). GEE collects the image to fit a 256x256 grid and GEE select the pyramid with the closest scale to that of your analysis and re-samples as needed. When we do re-sample, it uses nearest neighbor by default.\n\nScale. Source: GEE\nLet’s see an example, first load an image\nvar image = ee.Image(‘LANDSAT/LC08/C01/T1/LC08_044034_20140318’); var rgbVis = { bands: [‘B4’, ‘B3’, ‘B2’], min: 5964.56, max: 11703.44 }; Map.addLayer(image, rgbVis, “Landsat 8”);\nScale. Source: GEE\nNext, select a band 4 and then change the scale\nvar band_4 = image.select(‘B4’); var printAtScale = function(scale) { print(‘Pixel value at’+scale+’ meters scale’, band_4.reduceRegion({ reducer: ee.Reducer.first(), geometry: band_4.geometry().centroid(), // The scale determines the pyramid level from which to pull the input scale: scale }).get(‘B4’)); }; printAtScale(10); // 8883 printAtScale(30); // 8883 printAtScale(50); // 8337 printAtScale(70); // 9215 printAtScale(200); // 8775 printAtScale(500); // 8300 Copy Code\nSource: Code example\n\n\n5.1.1.3 Projection\nGEE converts all data into the Mercator projection(EPSG:3867). As a result, the operations of the projection are decided by the output.\n\nSource: GEE\n\n\n\n5.1.2 GEE in action(how we use it)\n\n5.1.2.1 Building blocks of GEE\nObject can be vector, raster, feature, string and number. Each of objects belong to a class and each class have specific functions.\n\nSource: GEE\n\n\n5.1.2.2 What does GEE look like\n\nSource: Form of GEE\n\n\n5.1.2.3 Typical processes in GEE\nAfter we have lots of images(raster data) and these belong to an imagecollection. We can process geometry operations, methods and applications.\n\nGeometry operations\n\nJoins\nZonal statistics\nFiltering of images or specific values\n\nMethods\n\nMachine learning\nSupervised and unsupervised classification\nDeep learning with Tensor Flow\nExploring relationship between variables\nExploring relationship between variables\n\nApplications\n\nOnline charts\nScalable geopspatial applications with GEE data\nThese let us query the data with a user interface that then updates the results\n\n\n\n\n5.1.2.4 Reducing images by region\nWe load an image collection from a dates and place and want to reduce the collection to the extreme values for each pixel. In GEE this is termed reduceRegion(). If we want to use feature collection with many polygons we can do it by image.reduceRegions().\n\nSource: GEE\n\n\n5.1.2.5 Reducing images by neighbourhoods\nWe can use image neighbors instead of using polygons to reduce the collection.\n\nSource: GEE\n\n\n5.1.2.6 Joins and filtering\nWe can join image collections and feature collections. To use joins we have to put them within a filter.\n\nThe leftField is the index (or attribute) in the primary data\nThe rightField is the secondary data"
  },
  {
    "objectID": "week5.html#applications",
    "href": "week5.html#applications",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.2 Applications",
    "text": "5.2 Applications\nGoogle Earth Engine is used in so many different fields and is very useful. This has made remote sensing analysis faster and more accessible.(M. Amani et al. ,2020). However, I consider environmental monitoring to be the most powerful application of them all. Environmental monitoring allows us to track land use change, monitor deforestation, detect floods, and detect damage. It can also monitor air quality, surface temperature, water quality, crop patterns and soil health."
  },
  {
    "objectID": "week5.html#personal-reflection",
    "href": "week5.html#personal-reflection",
    "title": "5  Introduction to Google Earth Engine",
    "section": "5.3 Personal Reflection",
    "text": "5.3 Personal Reflection\nThis week we learned about Google Earth Engine (GEE). In fact, before I studied GEE, I had Google Earth installed on my personal computer. The reason is that I wanted to see landmarks around the world through 3D building information provided by Google. At this time, for the first time, I found out that Google Earth is basically using LandSAT8(What we learned in previous week) satellite images for the entire earth, although it varies depending on the region. In this lecture, I created GEE account and personally experienced its advantages. I was surprised by the fact that if you sign up for GEE, you can program yourself and that anyone can view satellite data from around the world free of charge. I was also surprised that there was an easy to follow instruction manual."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Classification1",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nIn this week, we will focused on the use of classification techniques within remotely sensed data.\n\n6.1.1 How to classify remotely sensed data\n\n6.1.1.1 Classification trees\n\nClassify data into two or more discrete categories\nOutput variable is categoriesed such as religion, sex, nationality\nTop-down approach\nThe final leaves can be a mixture of the categories(impure), so we quantify this with the Gini Impurity\n\n\nSource:An Introduction to Data Science, Dr Saed Sayad\n\n\n6.1.1.2 Regression trees\n\nRegression trees is decision tree model with regression\nOutput variable is continuous values such as height, weight or temperature\nBottom-up approach\nSubset the data into smaller chunks\n\nSource:Luka Beverin\n\n\n\n6.1.1.3 Overfitting\n\nWhat if we have a leaf with just one person or one pixel value? = overfitting\n\nBias means difference between predicted value and true value(oversimplifies model)\nVariance is variability of model for a given point\n\n\n\nSource:Seema Singh\n\n\n6.1.1.4 Prevent overfitting\n\nWe can fix it by limiting how trees grow, for example we can set a minimum number of pixels in a leaf(20 is often used)\nSource:ML Wiki\nAlso we can fix it by weakest link pruning (with tree score)\n\nuse one less leaf, remove a leaf = sub-tree, SSR will get larger = termed PRUNING or cost complexity pruning\nSum for the tree\nTree score = SSR + tree penalty (alpha) * T (number of leaves) Lower means better\n\n\n\n\nThere is another method… Random Forest\n\nEnsemble machine learning model\nAll decision trees are grown by randomly extracting sub-datasets\nA single data may be selected multiple times as it allows redundancy\nFind the overall value which got more values based on all the trees\n\n\n\nSource:Rosaria Silipo\n\n\n\n6.1.2 Image classification\nThere are three types of image classification.\n\n\n\n\n\n\n\nSupervised Classification\nUnsupervised Classification\n\n\n\n\nPattern recognition or machine learning\nclustering\n\n\nParametric (normal distribution) : Maximum likelihood\nk-means\n\n\nnon parametric (not normal) : Support Vector Machine, Neural Networks\nISODATA\n\n\n\n\nSource:GIS Geography"
  },
  {
    "objectID": "week6.html#applications",
    "href": "week6.html#applications",
    "title": "6  Classification1",
    "section": "6.2 Applications",
    "text": "6.2 Applications\nThis week I read about “VIIRS Day/Night Band to Measure Electricity Supply Reliability: Preliminary Results from Maharashtra, India”. In this study, M. Amani et al (2016). used VIIRS (Visible Infrared Imaging Radiometer Suite) images to measure the reliability of electricity supply in Maharashtra, India. In this study, they used the Random Forest model we learned about this week. This study provides a reliable and accurate method for measuring electricity supply reliability, as the VIIRS Day/Night Band data (providing high spatial and temporal resolution images of nighttime illumination) was able to capture both planned and unplanned outages. Therefore, this study will be a useful tool for measuring electricity supply reliability in developing countries where settlements occur continuously and frequently."
  },
  {
    "objectID": "week6.html#personal-reflection",
    "href": "week6.html#personal-reflection",
    "title": "6  Classification1",
    "section": "6.3 Personal Reflection",
    "text": "6.3 Personal Reflection\nAs a surveying engineer, I have always been obsessed with accurate figures. This background is why it is important to choose the model with the highest accuracy. And even in the real world, it’s common to prioritize accuracy because most of us aim for profit. In this week’s lesson, I learned that classification methods fundamentally analyze data differently, which affects the ability to build accurate models. Although I did not fully understand the mathematical principles of each classification method, my goal is to build a model that is close to perfection by understanding it more clearly. However, in the field of social science research, since there is a possibility of understanding a phenomenon and inducing certain results rather than simply accurately predicting a phenomenon, interpretability should also be considered."
  },
  {
    "objectID": "index.html#who-am-i",
    "href": "index.html#who-am-i",
    "title": "RS notebook",
    "section": "Who am I?",
    "text": "Who am I?\nI’m Sohyun Park and I’m a Master’s student of Urban Spatial Science in the CASA(Center for Advanced Spatial Analysis. I joined the company(LX ; a public organization that has been offering survey services and various cadastral spatial data science since 1977) as an engineer in 2019."
  },
  {
    "objectID": "index.html#brief-introduce-about-this-learning-diary",
    "href": "index.html#brief-introduce-about-this-learning-diary",
    "title": "RS notebook",
    "section": "Brief introduce about this learning Diary",
    "text": "Brief introduce about this learning Diary\nIn this term, I’m taking a module CASA0023: Remotely Sensing Cities and Environment. This website contains weekly learning material with Summary, Applications and Personal Reflection."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Lopez Ornelas, Fernanda. 2016. “The Mexican Water Forest: Benefits of Using Remote Sensing Techniques to Assess Changes in Land Use and Land Cover.” PhD thesis. https://doi.org/10.13140/RG.2.2.11855.43685.\nS. Campbell et al., “Sensor Technology in Autonomous Vehicles : A review,” 2018 29th Irish Signals and Systems Conference (ISSC), Belfast, UK, 2018, pp. 1-4, https://ieeexplore.ieee.org/document/8585340.\nAimin Li & Guangping Xia (2021) The influence of geometric correction on the accuracy of the extraction of the remote sensing reflectance of water, International Journal of Remote Sensing, 42:6, 2280-2291, DOI: 10.1080/2150704X.2020.1847350\nPolicy Planning Section, General Affairs Division,Bureau of Environment, Tokyo Metropolitan Government(2019) Zero Emission Tokyo Strategy https://www.kankyo.metro.tokyo.lg.jp/en/about_us/zero_emission_tokyo/strategy.files/Full-ver.ZE-strategy0311.pdf\nM. Amani et al., “Google Earth Engine Cloud Computing Platform for Remote Sensing Big Data Applications: A Comprehensive Review,” in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, vol. 13, pp. 5326-5350, 2020, doi: 10.1109/JSTARS.2020.3021052. https://ieeexplore.ieee.org/document/9184118.\nMann, M.L.; Melaas, E.K.; Malik, A. Using VIIRS Day/Night Band to Measure Electricity Supply Reliability: Preliminary Results from Maharashtra, India. Remote Sens. 2016, 8, 711. https://doi.org/10.3390/rs8090711\nBiswajeet Pradhan, Remote sensing and GIS-based landslide hazard analysis and cross-validation using multivariate logistic regression model on three test areas in Malaysia, Advances in Space Research, Volume 45, Issue 10, 2010, Pages 1244-1256, ISSN 0273-1177, https://doi.org/10.1016/j.asr.2010.01.006\nLee, Kanghyun, and Robert D. Brown. 2022. “Effects of Urban Landscape and Sociodemographic Characteristics on Heat-Related Health Using Emergency Medical Service Incidents.” International Journal of Environmental Research and Public Health 19 (3): 1287. https://doi.org/10.3390/ijerph19031287."
  }
]